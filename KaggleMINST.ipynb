{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./input/train.csv\"); #Load training dataset from the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./input/test.csv\"); #Load test dataset from the input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label = train.label\n",
    "train = train.drop(train.columns[0],axis=1) #copy the label column and remove it from train variable\n",
    "#This is done to seperate the labels from features.\n",
    "#The features should be in seprate variable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.head(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000,)\n",
      "(42000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQFKEH0iK8ANJ/Rd45+cZYaSmLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x164ecc75240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Have Validation set to validate the train results at each iteration\n",
    "#mapping training and validation data to X and y variables as numpy object.\n",
    "X_train = train[:-5000];\n",
    "y_train = label[:-5000];\n",
    "X_train = train.as_matrix().astype(np.float32);\n",
    "y_train = label.as_matrix().astype(np.float32);\n",
    "X_valid = train.iloc[-5000:].as_matrix().astype(np.float32)\n",
    "y_valid = label.iloc[-5000:].as_matrix().astype(np.float32)\n",
    "print (y_train.shape)\n",
    "print (X_train.shape)\n",
    "plt.imshow(X_valid[1].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 float32 float32\n"
     ]
    }
   ],
   "source": [
    "#mapping y labels to vector of size 10(labels)\n",
    "#example y = 2 ==> y = [0,0,1,0,0,0,0,0,0,0] for training the classification model\n",
    "num_labels = 10\n",
    "X_test = test.as_matrix().astype(np.float32)\n",
    "X_valid = X_valid.astype(np.float32)\n",
    "y_valid = y_valid.astype(np.float32)\n",
    "y_train = (np.arange(num_labels) == y_train[:,None]).astype(np.float32)\n",
    "y_valid = (np.arange(num_labels) == y_valid[:,None]).astype(np.float32)\n",
    "print(X_train.dtype,y_train.dtype,X_valid.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "num_steps = 12000\n",
    "batch_size = 100\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "def initNN():\n",
    "    Weight = tf.Variable(tf.truncated_normal([5,5,1,32]))\n",
    "    Weight1 = tf.Variable(tf.truncated_normal([5,5,32,64]))\n",
    "    Weight2 = tf.Variable(tf.truncated_normal([7*7*64,1024]))\n",
    "    Weight3 = tf.Variable(tf.truncated_normal([1024,num_labels]))\n",
    "    bias = tf.Variable(tf.zeros([32]))\n",
    "    bias1 = tf.Variable(tf.zeros([64]))\n",
    "    bias2 = tf.Variable(tf.zeros([1024]))\n",
    "    bias3 = tf.Variable(tf.zeros([num_labels]))\n",
    "    return [Weight,bias,Weight1,bias1,Weight2,bias2,Weight3,bias3]\n",
    "\n",
    "def forwardCNN(X,W):\n",
    "    X = tf.reshape(X,[-1,28,28,1])\n",
    "    \n",
    "    H1 = conv2d(X,W[0])+W[1];\n",
    "    H1 = tf.nn.relu(H1);\n",
    "    H2 = max_pool_2x2(H1);\n",
    "    \n",
    "    H2 = conv2d(H2,W[2])+W[3];\n",
    "    H2 = tf.nn.relu(H2);\n",
    "    H3 = max_pool_2x2(H2);\n",
    "    \n",
    "    H3 = tf.reshape(H3, [-1, 7*7*64])\n",
    "    H3 = tf.matmul(H3,W[4])+W[5];\n",
    "    H3 = tf.nn.relu(H3);\n",
    "    \n",
    "    H3 = tf.nn.dropout(H3,0.6)\n",
    "    \n",
    "    H4 = tf.matmul(H3,W[6])+W[7];\n",
    "    return H4\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    X = tf.placeholder(tf.float32,[None,784])\n",
    "    y = tf.placeholder(tf.float32,[None,num_labels])\n",
    "    W = initNN()\n",
    "    H2 = forwardCNN(X,W)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(H2,y))\n",
    "    optimizer = tf.train.AdamOptimizer(1e-2).minimize(loss)\n",
    "    train_prediction = (H2)\n",
    "    valid_prediction = (forwardCNN(X_valid,W))\n",
    "    test = tf.nn.softmax(H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 17756464.000000\n",
      "mini batch accuracy:  8.0\n",
      "Validation accuracy:  16.38\n",
      "Minibatch loss at step 2000: 2603.605469\n",
      "mini batch accuracy:  99.0\n",
      "Validation accuracy:  97.08\n",
      "Minibatch loss at step 4000: 0.000000\n",
      "mini batch accuracy:  100.0\n",
      "Validation accuracy:  98.44\n",
      "Minibatch loss at step 6000: 4209.136719\n",
      "mini batch accuracy:  97.0\n",
      "Validation accuracy:  99.02\n",
      "Minibatch loss at step 8000: 1190.541260\n",
      "mini batch accuracy:  99.0\n",
      "Validation accuracy:  98.92\n",
      "Minibatch loss at step 10000: 518.546997\n",
      "mini batch accuracy:  99.0\n",
      "Validation accuracy:  98.18\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    eq = (np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "    return ((100.0 * np.sum(eq))/eq.size)\n",
    "Result = [];\n",
    "sess = {};\n",
    "with tf.Session(graph=graph) as session:\n",
    "    sess = session;\n",
    "    tf.global_variables_initializer().run()\n",
    "    offset=0\n",
    "    print(\"Initialized\")\n",
    "    for step in range(num_steps):\n",
    "        offset = (step * batch_size) % (X_train.shape[0] - batch_size)\n",
    "        batch_data = X_train[offset:(offset + batch_size), :]\n",
    "        batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "        feed_dict = {X : batch_data, y : batch_labels}\n",
    "        _, l, predictions = session.run([optimizer, loss, train_prediction],feed_dict=feed_dict)\n",
    "        if (step % 2000 == 0):\n",
    "            print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "            print(\"mini batch accuracy: \", accuracy(predictions, batch_labels))            \n",
    "            print(\"Validation accuracy: \", accuracy(valid_prediction.eval(), y_valid))        \n",
    "    count = 0;\n",
    "    result = [];\n",
    "    for i in range(int(X_test.shape[0]/100)):\n",
    "        result.extend(np.argmax(session.run([test],feed_dict={X:X_test[count:count+100]})[0],1))\n",
    "        count = count+100;\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000\n"
     ]
    }
   ],
   "source": [
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_label = pd.DataFrame(data=result,columns=['Label']);\n",
    "test_label.to_csv(path_or_buf=open('test_result.csv','w'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27990</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27991</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27992</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27993</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27994</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label\n",
       "27990      7\n",
       "27991      6\n",
       "27992      1\n",
       "27993      9\n",
       "27994      7\n",
       "27995      9\n",
       "27996      7\n",
       "27997      3\n",
       "27998      9\n",
       "27999      2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
